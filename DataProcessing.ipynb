{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c4e6bc-4af5-40fb-b4c8-b648b9e8bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from data_utils import normalize_data, \\\n",
    "                       flatten_data, \\\n",
    "                       add_row_padding, \\\n",
    "                       split_fluxes, \\\n",
    "                       fuse_amplitude_and_phase, \\\n",
    "                       save_numpy_array, \\\n",
    "                       save_scaler\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33e0ad-efbc-48f2-8719-afb1399865b4",
   "metadata": {},
   "source": [
    "# 0. Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997323f-4daf-401a-9ebe-b47a326b1f0a",
   "metadata": {},
   "source": [
    "With this notebook we will process and save the flux, amplitude and phase data, dividing them into train, validation and test datasets.\n",
    "The dataset sizes are the following:\n",
    "- Train: 70000\n",
    "- Validation: 10000\n",
    "- Test: 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8def7-7920-4fa5-ada6-254e6591299d",
   "metadata": {},
   "source": [
    "# 1. Flux Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "348bdb9f-97f9-40f1-b91d-172e7d62bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import ORIGINAL_FLUXES_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de30464-9d6e-4c62-91db-3b1b8e9c1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 70000\n",
    "VALIDATION_SIZE = 10000\n",
    "TEST_SIZE = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6859748-906e-42b4-b107-8e1b6b4171c6",
   "metadata": {},
   "source": [
    "## 1.1 Flux Data for Fully Connected Architectures\n",
    "For the FC Architectures we need to:\n",
    " - Normalize\n",
    " - Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ba34e0-7942-4f96-945d-eba3ab159354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load flux data\n",
    "fluxes_array = np.load(ORIGINAL_FLUXES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6474d7e4-db25-42ba-a370-f14edf05c7e6",
   "metadata": {},
   "source": [
    "Check the shape of the data, there should be 90000 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9246128e-c84b-484e-9fc7-5276949db8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 55, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fluxes_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027697ac-2ebc-4585-ac41-504641ab70a8",
   "metadata": {},
   "source": [
    "Process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f85a92-3700-4e7a-b35c-83ad29361144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "fc_normalized_fluxes_array, fc_flux_scaler = normalize_data(fluxes_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994ede3e-890c-4776-8a20-92e6b1f07397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten data\n",
    "fc_flattened_normalized_fluxes_array = flatten_data(fc_normalized_fluxes_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "931da1cb-2ab6-46a4-b344-6e5f8cd32828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_fc_fluxes, val_fc_fluxes, test_fc_fluxes = split_fluxes(fc_flattened_normalized_fluxes_array,\n",
    "                                                              TRAIN_SIZE,\n",
    "                                                              VALIDATION_SIZE,\n",
    "                                                              TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1795e73-29d1-49ba-b492-99220a0021cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 1320)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fc_fluxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbe2e19b-b54f-4342-9dcb-492bf9e77679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1320)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_fc_fluxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9c0ae22-e570-4ac3-9453-b0d19e79b9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1320)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc_fluxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e124d-71e5-43c1-a250-39afabda8ed0",
   "metadata": {},
   "source": [
    "Save data and scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f46a144-65f4-4d20-9bee-c1b4bb413333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data paths\n",
    "from constants import TRAIN_FC_FLUXES_PATH, \\\n",
    "                      VALIDATION_FC_FLUXES_PATH, \\\n",
    "                      TEST_FC_FLUXES_PATH, \\\n",
    "                      FC_FLUX_SCALER_PATH\n",
    "\n",
    "# Save train fluxes\n",
    "save_numpy_array(train_fc_fluxes, TRAIN_FC_FLUXES_PATH)\n",
    "# Save validation fluxes\n",
    "save_numpy_array(val_fc_fluxes, VALIDATION_FC_FLUXES_PATH)\n",
    "# Save test fluxes\n",
    "save_numpy_array(test_fc_fluxes, TEST_FC_FLUXES_PATH)\n",
    "# Save fully connected flux scaler\n",
    "save_scaler(fc_flux_scaler, FC_FLUX_SCALER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f25ad-cae4-4bec-948e-b1ac4e949813",
   "metadata": {},
   "source": [
    "## 1.2 Flux data for CNN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e21f1-97ef-4501-acbf-05e19275f2f6",
   "metadata": {},
   "source": [
    "For the CNN Architectures we need to:\n",
    "- Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc369bf1-f419-4b19-90ef-cea0435e2c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load flux data\n",
    "fluxes_array = np.load(ORIGINAL_FLUXES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd2659-4cf9-45b6-888f-728494c0b9c9",
   "metadata": {},
   "source": [
    "Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3de034d-ca30-442d-b7ff-3f5ebe12912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "conv_normalized_fluxes_array, conv_flux_scaler = normalize_data(fluxes_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ec7b432-b4fa-4b89-9459-5390f913e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_conv_fluxes, val_conv_fluxes, test_conv_fluxes = split_fluxes(conv_normalized_fluxes_array,\n",
    "                                                                    TRAIN_SIZE,\n",
    "                                                                    VALIDATION_SIZE,\n",
    "                                                                    TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b98e40bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 55, 24)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_conv_fluxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "736bc2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 55, 24)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_conv_fluxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c7860fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 55, 24)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conv_fluxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f37fa79-675f-4e3c-ba9f-6418826f0edb",
   "metadata": {},
   "source": [
    "Save data and scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81ef8ba2-38a5-4c8f-b499-1f3b2a5e92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data paths\n",
    "from constants import TRAIN_CNN_FLUXES_PATH, \\\n",
    "                      VALIDATION_CNN_FLUXES_PATH, \\\n",
    "                      TEST_CNN_FLUXES_PATH, \\\n",
    "                      CNN_FLUX_SCALER_PATH\n",
    "\n",
    "# Save train fluxes\n",
    "save_numpy_array(train_conv_fluxes, TRAIN_CNN_FLUXES_PATH)\n",
    "# Save validation fluxes\n",
    "save_numpy_array(val_conv_fluxes, VALIDATION_CNN_FLUXES_PATH)\n",
    "# Save test fluxes\n",
    "save_numpy_array(test_conv_fluxes, TEST_CNN_FLUXES_PATH)\n",
    "# Save fully connected flux scaler\n",
    "save_scaler(conv_flux_scaler, CNN_FLUX_SCALER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eced453-db2a-4dd1-80e9-106508aa8741",
   "metadata": {},
   "source": [
    "## 1.3 Flux data for Autoencoder Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6795f98-72a3-4827-93ac-6671187dcc07",
   "metadata": {},
   "source": [
    "For the Autoencoder Architecture we need to:\n",
    "- Add padding\n",
    "- Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "973e2b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load flux data\n",
    "fluxes_array = np.load(ORIGINAL_FLUXES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfef86b-8e6d-4c8f-949b-cc2f17db843e",
   "metadata": {},
   "source": [
    "Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6a767b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add padding to data\n",
    "padded_fluxes = add_row_padding(fluxes_array, top_rows=1, bottom_rows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47493422-c642-4477-9198-9484333da837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "normalized_padded_fluxes_array, autoencoder_flux_scaler = normalize_data(padded_fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d72f22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_autoencoder_fluxes, val_autoencoder_fluxes, test_autoencoder_fluxes = split_fluxes(normalized_padded_fluxes_array,\n",
    "                                                                                         TRAIN_SIZE,\n",
    "                                                                                         VALIDATION_SIZE,\n",
    "                                                                                         TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c80d0ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 56, 24)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_autoencoder_fluxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b40bb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 56, 24)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_autoencoder_fluxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38222a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 56, 24)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_autoencoder_fluxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e45c2-7880-47c9-a0d7-151717a460c4",
   "metadata": {},
   "source": [
    "Save data and scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7263ba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data paths\n",
    "from constants import TRAIN_AUTOENCODER_FLUXES_PATH, \\\n",
    "                      VALIDATION_AUTOENCODER_FLUXES_PATH, \\\n",
    "                      TEST_AUTOENCODER_FLUXES_PATH, \\\n",
    "                      AUTOENCODER_FLUX_SCALER_PATH\n",
    "\n",
    "# Save train fluxes\n",
    "save_numpy_array(train_autoencoder_fluxes, TRAIN_AUTOENCODER_FLUXES_PATH)\n",
    "# Save validation fluxes\n",
    "save_numpy_array(val_autoencoder_fluxes, VALIDATION_AUTOENCODER_FLUXES_PATH)\n",
    "# Save test fluxes\n",
    "save_numpy_array(test_autoencoder_fluxes, TEST_AUTOENCODER_FLUXES_PATH)\n",
    "# Save fully connected flux scaler\n",
    "save_scaler(autoencoder_flux_scaler, AUTOENCODER_FLUX_SCALER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54482e-938e-49ea-90c1-cc0203b460a6",
   "metadata": {},
   "source": [
    "# 2. Amplitude and Phase Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08674fac-66b5-4af3-b1b0-07e393cf6c57",
   "metadata": {},
   "source": [
    "## 2.1 Amplitude and Phase for Fully Connected Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7dca6e-9861-46e6-ab10-13a5c6f7b37e",
   "metadata": {},
   "source": [
    "For the FC architectures we need to:\n",
    "- Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8539eeea-dc0f-45a9-8a2e-ad047b6be521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import ORIGINAL_SLM_FOLDER, \\\n",
    "                      ORIGINAL_AMPLITUDE_FILENAME, \\\n",
    "                      ORIGINAL_PHASE_FILENAME, \\\n",
    "                      TRAIN_AMP_PHASE_FILE_SUFFIXES, \\\n",
    "                      VAL_AMP_PHASE_FILE_SUFFIX, \\\n",
    "                      TEST_AMP_PHASE_FILE_SUFFIX, \\\n",
    "                      NUMPY_SUFFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04413400-38b5-4c54-a8d5-16a9eea6d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "amplitudes = []\n",
    "phases = []\n",
    "\n",
    "for file_number in TRAIN_AMP_PHASE_FILE_SUFFIXES + [VAL_AMP_PHASE_FILE_SUFFIX] + [TEST_AMP_PHASE_FILE_SUFFIX]:\n",
    "    amp_filename = f\"{ORIGINAL_SLM_FOLDER}{file_number}/{ORIGINAL_AMPLITUDE_FILENAME}\"\n",
    "    phase_filename = f\"{ORIGINAL_SLM_FOLDER}{file_number}/{ORIGINAL_PHASE_FILENAME}\"\n",
    "    amplitudes.append(np.float32(np.load(amp_filename)))\n",
    "    phases.append(np.float32(np.load(phase_filename)))\n",
    "\n",
    "amplitudes = np.concatenate(amplitudes, axis=0)\n",
    "phases = np.concatenate(phases, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7b4c6-31fe-42c9-91b4-7ae78b162cdb",
   "metadata": {},
   "source": [
    "Now process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c98e3689-5bfe-4a2b-909b-5586be6cc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "normalized_amplitudes, fc_amplitude_scaler = normalize_data(amplitudes)\n",
    "normalized_phases, fc_phase_scaler = normalize_data(phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a97e25b-70de-4f45-afc6-804d71a56570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 96, 96)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_amplitudes.shape\n",
    "normalized_phases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c464b4ca-7b04-42e7-a789-01f1eb55402f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 2, 96, 96)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack amplitude and phase\n",
    "amp_phase_array = fuse_amplitude_and_phase(normalized_amplitudes, normalized_phases)\n",
    "amp_phase_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21536df6-2ae0-4dbc-93c4-6fd65193366c",
   "metadata": {},
   "source": [
    "Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dd35f0a-764a-40cb-8b75-1b4042aba770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import TRAIN_FC_AMP_PHASE_PATH, \\\n",
    "                      VALIDATION_FC_AMP_PHASE_PATH, \\\n",
    "                      TEST_FC_AMP_PHASE_PATH, \\\n",
    "                      FC_AMP_SCALER_PATH, \\\n",
    "                      FC_PHASE_SCALER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8dc93eea-8c06-42e1-8d83-562904a1e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 10000\n",
    "# Save train data\n",
    "for train_file in TRAIN_AMP_PHASE_FILE_SUFFIXES:\n",
    "    filename = f\"{TRAIN_FC_AMP_PHASE_PATH}{train_file}{NUMPY_SUFFIX}\"\n",
    "    save_numpy_array(amp_phase_array[start:end], filename)\n",
    "    start += 10000\n",
    "    end += 10000\n",
    "\n",
    "# Save validation data\n",
    "save_numpy_array(amp_phase_array[start:end], VALIDATION_FC_AMP_PHASE_PATH)\n",
    "start += 10000\n",
    "end += 10000\n",
    "\n",
    "# Save test data\n",
    "save_numpy_array(amp_phase_array[start:end], TEST_FC_AMP_PHASE_PATH)\n",
    "\n",
    "# Save scalers\n",
    "save_scaler(fc_amplitude_scaler, FC_AMP_SCALER_PATH)\n",
    "save_scaler(fc_phase_scaler, FC_PHASE_SCALER_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sail-env",
   "language": "python",
   "name": "sail-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f127d7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 09:06:16.507722: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 09:06:17.195856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from constants import FLUXES_FOLDER, \\\n",
    "                      SLM_FOLDER\n",
    "\n",
    "from data_utils import process_amp_phase_data, \\\n",
    "                       add_row_padding\n",
    "\n",
    "from plot_utils import plot_map, \\\n",
    "                       plot_model_history, \\\n",
    "                       plot_autoencoder\n",
    "\n",
    "from modeling_utils import create_autoencoder_for_flux, \\\n",
    "                           compile_model, \\\n",
    "                           train_model, \\\n",
    "                           store_model\n",
    "\n",
    "from configurations import AutoEncoderConfiguration, \\\n",
    "                           EncoderConvolutionalConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2339e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes_filename = \"all_fluxes.npy\"\n",
    "amplitudes_filename = \"complexsine_pupamp.npy\"\n",
    "phases_filename = \"complexsine_pupphase.npy\"\n",
    "\n",
    "fluxes_path = f\"{FLUXES_FOLDER}/{fluxes_filename}\"\n",
    "amplitudes_path = f\"{SLM_FOLDER}/{amplitudes_filename}\"\n",
    "phases_path = f\"{SLM_FOLDER}/{phases_filename}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f68013",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fluxes_array, val_fluxes_array, train_amp_phase_array, val_amp_phase_array, scalers = \\\n",
    "    process_amp_phase_data(\n",
    "        fluxes_path, \n",
    "        amplitudes_path,\n",
    "        phases_path,\n",
    "        n_points=10000,\n",
    "        trim_amplitude=True,\n",
    "        trim_phase=True,\n",
    "        normalize_flux=True,\n",
    "        normalize_amplitude=True,\n",
    "        shuffle=False,\n",
    "        flatten_fluxes=False,\n",
    "        split=True,\n",
    "        val_ratio=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f465c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fluxes_array = add_row_padding(train_fluxes_array, 1)\n",
    "val_fluxes_array = add_row_padding(val_fluxes_array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6aa69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t=== FluxAutoencoder ===\n",
      "\t*ARCHITECTURE HYPERPARAMETERS:\n",
      "\t\t-Autoencoder\n",
      "\t\t-Input shape: (56, 24)\n",
      "\t\t-Convolutional Layers: [256, 128, 16, 4] (Inverse in the decoder)\n",
      "\t\t-Convolutonal Kernels: [(3, 3), (3, 3), (3, 3), (3, 3)] (Inverse in the decoder)\n",
      "\t\t-Convolutional Activation: relu\n",
      "\t\t-Output Layer Activation: linear\n",
      "\t\n",
      "\t*COMPILATION HYPERPARAMETERS:\n",
      "\t\t-Optimizer: ADAM lr=0.001, beta_1=0.9, beta_2=0.999\n",
      "\t\t-Loss Function: MSE\n",
      "\t\t-Metric: MSE\n",
      "\t\n",
      "\t* TRAINING HYPERPARAMETERS:\n",
      "\t\t-Epochs: 1\n",
      "\t\t-Batch size: 16\n",
      "\t\t-Callbacks:\n",
      "\t\t\t-ReduceLROnPlateau: MSE 8 x0.1\n",
      "\t\t\t-Early Stop: MSE 15\n",
      "\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 09:06:21.631284: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 09:06:21.670808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 09:06:21.671094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 09:06:21.673855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 09:06:21.674126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 09:06:21.674330: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 09:06:22.211495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 09:06:22.211737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 09:06:22.211940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 09:06:22.212108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2103 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model_configuration = AutoEncoderConfiguration(train_fluxes_array)\n",
    "print(model_configuration.get_description())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a525a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FluxAutoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 56, 24, 256)       2560      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 56, 24, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 28, 12, 256)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 12, 128)       295040    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 12, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 6, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 6, 16)         18448     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 6, 16)         2320      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 7, 3, 16)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " pre_bottleneck (Conv2D)     (None, 7, 3, 4)           580       \n",
      "                                                                 \n",
      " bottleneck (Conv2D)         (None, 7, 3, 4)           148       \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  (None, 14, 6, 4)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 6, 16)         592       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 14, 6, 16)         2320      \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSamplin  (None, 28, 12, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 12, 128)       18560     \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 12, 128)       147584    \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSamplin  (None, 56, 24, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 56, 24, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 56, 24, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 56, 24, 1)         2305      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2113369 (8.06 MB)\n",
      "Trainable params: 2113369 (8.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_autoencoder_for_flux(\n",
    "    *model_configuration.unpack_architecture_hyperparameters()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43aabee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_model(\n",
    "    model,\n",
    "    *model_configuration.unpack_compilation_hyperparameters()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255fe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 09:06:25.103869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-12-04 09:06:25.883519: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-04 09:06:25.883564: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-04 09:06:26.692963: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff1b112c540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-04 09:06:26.693004: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2023-12-04 09:06:26.698021: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-04 09:06:26.817457: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-12-04 09:06:27.238161: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561/563 [============================>.] - ETA: 0s - loss: 0.2688 - mean_squared_error: 0.2688"
     ]
    }
   ],
   "source": [
    "history = train_model(\n",
    "    model,\n",
    "    train_fluxes_array,\n",
    "    train_fluxes_array,\n",
    "    val_fluxes_array,\n",
    "    val_fluxes_array,\n",
    "    *model_configuration.unpack_training_hyperparameters()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f115f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2972054",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_autoencoder(model, val_fluxes_array[757])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19afa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_autoencoder(model, val_fluxes_array[758])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_model(model,\n",
    "            model.name,\n",
    "            model_configuration.get_description())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9cb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206eff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in encoder.layers:\n",
    "    layer.trainable = False\n",
    "    if layer.name == \"bottleneck\":\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce93fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_input = encoder.output\n",
    "conv_layers = keras.layers.UpSampling2D(size=(1,2))(conv_input)\n",
    "conv_layers = keras.layers.UpSampling2D(size=(2,2))(conv_layers)\n",
    "conv_layers = keras.layers.UpSampling2D(size=(2,2))(conv_layers)\n",
    "conv_layers = keras.layers.UpSampling2D(size=(2,2))(conv_layers)\n",
    "conv_layers = keras.layers.UpSampling2D(size=(2,2))(conv_layers)\n",
    "\n",
    "conv_model = keras.Model(inputs=encoder.input, outputs=conv_layers)\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770eb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configuration = EncoderConvolutionalConfiguration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b11ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iac-env",
   "language": "python",
   "name": "iac-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
